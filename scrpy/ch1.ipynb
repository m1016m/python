{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'<html>\\n<head>\\n<title>A Useful Page</title>\\n</head>\\n<body>\\n<h1>An Interesting Title</h1>\\n<div>\\nLorem ipsum dolor sit amet, consectetur adipisicing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.\\n</div>\\n</body>\\n</html>\\n'\n"
     ]
    }
   ],
   "source": [
    "from urllib.request import urlopen\n",
    "\n",
    "html = urlopen('http://pythonscraping.com/pages/page1.html')\n",
    "print(html.read())#调用html.read() 获取网页的HTML 内容"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<h1>An Interesting Title</h1>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<h1>An Interesting Title</h1>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "html = urlopen(\"http://www.pythonscraping.com/pages/page1.html\")\n",
    "bsObj = BeautifulSoup(html.read())\n",
    "print(bsObj.h1)\n",
    "#从网页中提取的<h1> 标签被嵌在BeautifulSoup 对象bsObj 结构的第二层（html → body → h1）。但是，当我们从对象里提取h1 标签的时候，可以直接调用它：\n",
    "bsObj.h1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<h1>An Interesting Title</h1>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#其实，下面的所有函数调用都可以产生同样的结果：\n",
    "bsObj.html.body.h1\n",
    "bsObj.body.h1\n",
    "bsObj.html.h1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<h1>An Interesting Title</h1>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bsObj.body.h1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<h1>An Interesting Title</h1>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bsObj.html.h1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 让我们看看爬虫import 语句后面的第一行代码，如何处理那里可能出现的异常：\n",
    "# html = urlopen(\"http://www.pythonscraping.com/pages/page1.html\")\n",
    "# 这行代码主要可能会发生两种异常：\n",
    "# • 网页在服务器上不存在（或者获取页面的时候出现错误）\n",
    "# • 服务器不存在\n",
    "# 第一种异常发生时，程序会返回HTTP 错误。HTTP 错误可能是“404 Page Not Found”“500Internal Server Error”等。\n",
    "# 所有类似情形，urlopen 函数都会抛出“HTTPError”异常。我们可以用下面的方式处理这种异常：\n",
    "try:\n",
    "    html = urlopen(\"http://www.pythonscraping.com/pages/page1.html\")\n",
    "except HTTPError as e:\n",
    "    print(e)\n",
    "# 返回空值，中断程序，或者执行另一个方案\n",
    "else:\n",
    "    pass\n",
    "# 程序继续。注意：如果你已经在上面异常捕捉那一段代码里返回或中断（break），\n",
    "# 那么就不需要使用else语句了，这段代码也不会执行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title could not be found\n"
     ]
    }
   ],
   "source": [
    "# getTitle 函数，可以返回网页的标题，如果获取网页的时候遇到问题就返回一个None 对象。在getTitle 函数里面，检查HTTPError，\n",
    "# 然后把两行BeautifulSoup 代码封装在一个try 语句里面。这两行中的任何一行有问题，AttributeError 都可能被抛出\n",
    "# （如果服务器不存在，html 就是一个None 对象，html.read() 就会抛出AttributeError）。如果你还希望能够很大程度地重用代码，那么拥有像\n",
    "# getSiteHTML 和getTitle 这样的通用函数（具有周密的异常处理功能）会让快速稳定地网络数据采集变得简单易行。\n",
    "from urllib.request import urlopen\n",
    "from urllib.error import HTTPError\n",
    "from bs4 import BeautifulSoup\n",
    "def getTitle(url):\n",
    "    try:\n",
    "        html = urlopen(url)\n",
    "    except HTTPError as e:\n",
    "        return None\n",
    "    try:\n",
    "        bsObj = BeautifulSoup(html.read())\n",
    "        title = bsObj.body.h1\n",
    "    except AttributeError as e:\n",
    "        return None\n",
    "        return title\n",
    "title = getTitle(\"http://www.pythonscraping.com/pages/page1.html\")\n",
    "if title == None:\n",
    "    print(\"Title could not be found\")\n",
    "else:\n",
    "    print(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anna\n",
      "Pavlovna Scherer\n",
      "Empress Marya\n",
      "Fedorovna\n",
      "Prince Vasili Kuragin\n",
      "Anna Pavlovna\n",
      "St. Petersburg\n",
      "the prince\n",
      "Anna Pavlovna\n",
      "Anna Pavlovna\n",
      "the prince\n",
      "the prince\n",
      "the prince\n",
      "Prince Vasili\n",
      "Anna Pavlovna\n",
      "Anna Pavlovna\n",
      "the prince\n",
      "Wintzingerode\n",
      "King of Prussia\n",
      "le Vicomte de Mortemart\n",
      "Montmorencys\n",
      "Rohans\n",
      "Abbe Morio\n",
      "the Emperor\n",
      "the prince\n",
      "Prince Vasili\n",
      "Dowager Empress Marya Fedorovna\n",
      "the baron\n",
      "Anna Pavlovna\n",
      "the Empress\n",
      "the Empress\n",
      "Anna Pavlovna's\n",
      "Her Majesty\n",
      "Baron\n",
      "Funke\n",
      "The prince\n",
      "Anna\n",
      "Pavlovna\n",
      "the Empress\n",
      "The prince\n",
      "Anatole\n",
      "the prince\n",
      "The prince\n",
      "Anna\n",
      "Pavlovna\n",
      "Anna Pavlovna\n"
     ]
    }
   ],
   "source": [
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "html = urlopen(\"http://www.pythonscraping.com/pages/warandpeace.html\")\n",
    "bsObj = BeautifulSoup(html)\n",
    "#通过BeautifulSoup 对象，我们可以用findAll 函数抽取只包含在<span class=\"green\"></span> 标签里的文字，这样就会得到一个人物名称的Python 列表\n",
    "nameList = bsObj.findAll(\"span\", {\"class\":\"green\"})#findAll(tagName, tagAttributes)\n",
    "for name in nameList:\n",
    "    print(name.get_text())\n",
    "#.get_text() 会把你正在处理的HTML 文档中所有的标签都清除，然后返回一个只包含文字的字符串。假如你正在处理一个包含许多超链接、段落和标\n",
    "#签的大段源代码，那么.get_text() 会把这些超链接、段落和标签都清除掉，只剩下一串不带标签的文字"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BeautifulSoup的find()和findAll()\n",
    "# BeautifulSoup 文档里两者的定义就是这样：\n",
    "#    findAll(tag, attributes, recursive, text, limit, keywords)\n",
    "#    find(tag, attributes, recursive, text, keywords)\n",
    "# 下面的代码将返回一个包含HTML 文档中所有标题标签的列表：\n",
    "# .findAll({\"h1\",\"h2\",\"h3\",\"h4\",\"h5\",\"h6\"})\n",
    "\n",
    "# 属性参数attributes 是用一个Python 字典封装一个标签的若干属性和对应的属性值。\n",
    "# 例如，下面这个函数会返回HTML 文档里红色与绿色两种颜色的span 标签：\n",
    "# .findAll(\"span\", {\"class\":{\"green\", \"red\"}})\n",
    "\n",
    "# 假如我们想查找前面网页中包含“the prince”内容的标签数量，我们可以把之前的findAll 方法换成下面的代码：\n",
    "# nameList = bsObj.findAll(text=\"the prince\")\n",
    "# print(len(nameList))\n",
    "# 输出结果为“7”\n",
    "\n",
    "# 范围限制参数limit，显然只用于findAll 方法\n",
    "\n",
    "# 关键词参数keyword，可以让你选择那些具有指定属性的标签。例如：\n",
    "# allText = bsObj.findAll(id=\"text\")\n",
    "# print(allText[0].get_text())\n",
    "\n",
    "# bsObj.findAll(id=\"text\")\n",
    "# bsObj.findAll(\"\", {\"id\":\"text\"})\n",
    "\n",
    "\n",
    "# 另外，用keyword 偶尔会出现问题，尤其是在用class 属性查找标签的时候，因为class 是Python 中受保护的关键字。也就是说，class 是Python 语言\n",
    "# 的保留字，在Python 程序里是不能当作变量或参数名使用的。假如你运行下面的代码，Python 就会因为你误用class 保留字而产生一个语法错误：\n",
    "# bsObj.findAll(class=\"green\")\n",
    "\n",
    "# 不过，你可以用BeautifulSoup 在class 后面增加一个下划线：\n",
    "# bsObj.findAll(class_=\"green\")\n",
    "\n",
    "# 另外，你也可以用属性参数把class 用引号包起来：\n",
    "# bsObj.findAll(\"\", {\"class\":\"green\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "<tr><th>\n",
      "Item Title\n",
      "</th><th>\n",
      "Description\n",
      "</th><th>\n",
      "Cost\n",
      "</th><th>\n",
      "Image\n",
      "</th></tr>\n",
      "\n",
      "\n",
      "<tr class=\"gift\" id=\"gift1\"><td>\n",
      "Vegetable Basket\n",
      "</td><td>\n",
      "This vegetable basket is the perfect gift for your health conscious (or overweight) friends!\n",
      "<span class=\"excitingNote\">Now with super-colorful bell peppers!</span>\n",
      "</td><td>\n",
      "$15.00\n",
      "</td><td>\n",
      "<img src=\"../img/gifts/img1.jpg\"/>\n",
      "</td></tr>\n",
      "\n",
      "\n",
      "<tr class=\"gift\" id=\"gift2\"><td>\n",
      "Russian Nesting Dolls\n",
      "</td><td>\n",
      "Hand-painted by trained monkeys, these exquisite dolls are priceless! And by \"priceless,\" we mean \"extremely expensive\"! <span class=\"excitingNote\">8 entire dolls per set! Octuple the presents!</span>\n",
      "</td><td>\n",
      "$10,000.52\n",
      "</td><td>\n",
      "<img src=\"../img/gifts/img2.jpg\"/>\n",
      "</td></tr>\n",
      "\n",
      "\n",
      "<tr class=\"gift\" id=\"gift3\"><td>\n",
      "Fish Painting\n",
      "</td><td>\n",
      "If something seems fishy about this painting, it's because it's a fish! <span class=\"excitingNote\">Also hand-painted by trained monkeys!</span>\n",
      "</td><td>\n",
      "$10,005.00\n",
      "</td><td>\n",
      "<img src=\"../img/gifts/img3.jpg\"/>\n",
      "</td></tr>\n",
      "\n",
      "\n",
      "<tr class=\"gift\" id=\"gift4\"><td>\n",
      "Dead Parrot\n",
      "</td><td>\n",
      "This is an ex-parrot! <span class=\"excitingNote\">Or maybe he's only resting?</span>\n",
      "</td><td>\n",
      "$0.50\n",
      "</td><td>\n",
      "<img src=\"../img/gifts/img4.jpg\"/>\n",
      "</td></tr>\n",
      "\n",
      "\n",
      "<tr class=\"gift\" id=\"gift5\"><td>\n",
      "Mystery Box\n",
      "</td><td>\n",
      "If you love suprises, this mystery box is for you! Do not place on light-colored surfaces. May cause oil staining. <span class=\"excitingNote\">Keep your friends guessing!</span>\n",
      "</td><td>\n",
      "$1.50\n",
      "</td><td>\n",
      "<img src=\"../img/gifts/img6.jpg\"/>\n",
      "</td></tr>\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 导航树\n",
    "# findAll 函数通过标签的名称和属性来查找标签 。但是如果你需要通过标签在文档中的位置来查找标签，该怎么办？这就是导航树（Navigating Trees）\n",
    "# 的作用。\n",
    "# bsObj.tag.subTag.anotherSubTag\n",
    "# 现在我们用虚拟的在线购物网站http://www.pythonscraping.com/pages/page3.html 作为要抓取的示例网页\n",
    "#想找出子标签，可以用.children 标签：\n",
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "html = urlopen(\"http://www.pythonscraping.com/pages/page3.html\")\n",
    "bsObj = BeautifulSoup(html)\n",
    "for child in bsObj.find(\"table\",{\"id\":\"giftList\"}).children:\n",
    "    print(child)\n",
    "# 这段代码会打印giftList 表格中所有产品的数据行。如果你用descendants() 函数而不是children() 函数，那么就会有二十几个标签打印出来，\n",
    "# 包括img 标签、span 标签，以及每个td 标签。掌握子标签与后代标签的差别十分重要！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "<tr class=\"gift\" id=\"gift1\"><td>\n",
      "Vegetable Basket\n",
      "</td><td>\n",
      "This vegetable basket is the perfect gift for your health conscious (or overweight) friends!\n",
      "<span class=\"excitingNote\">Now with super-colorful bell peppers!</span>\n",
      "</td><td>\n",
      "$15.00\n",
      "</td><td>\n",
      "<img src=\"../img/gifts/img1.jpg\"/>\n",
      "</td></tr>\n",
      "\n",
      "\n",
      "<tr class=\"gift\" id=\"gift2\"><td>\n",
      "Russian Nesting Dolls\n",
      "</td><td>\n",
      "Hand-painted by trained monkeys, these exquisite dolls are priceless! And by \"priceless,\" we mean \"extremely expensive\"! <span class=\"excitingNote\">8 entire dolls per set! Octuple the presents!</span>\n",
      "</td><td>\n",
      "$10,000.52\n",
      "</td><td>\n",
      "<img src=\"../img/gifts/img2.jpg\"/>\n",
      "</td></tr>\n",
      "\n",
      "\n",
      "<tr class=\"gift\" id=\"gift3\"><td>\n",
      "Fish Painting\n",
      "</td><td>\n",
      "If something seems fishy about this painting, it's because it's a fish! <span class=\"excitingNote\">Also hand-painted by trained monkeys!</span>\n",
      "</td><td>\n",
      "$10,005.00\n",
      "</td><td>\n",
      "<img src=\"../img/gifts/img3.jpg\"/>\n",
      "</td></tr>\n",
      "\n",
      "\n",
      "<tr class=\"gift\" id=\"gift4\"><td>\n",
      "Dead Parrot\n",
      "</td><td>\n",
      "This is an ex-parrot! <span class=\"excitingNote\">Or maybe he's only resting?</span>\n",
      "</td><td>\n",
      "$0.50\n",
      "</td><td>\n",
      "<img src=\"../img/gifts/img4.jpg\"/>\n",
      "</td></tr>\n",
      "\n",
      "\n",
      "<tr class=\"gift\" id=\"gift5\"><td>\n",
      "Mystery Box\n",
      "</td><td>\n",
      "If you love suprises, this mystery box is for you! Do not place on light-colored surfaces. May cause oil staining. <span class=\"excitingNote\">Keep your friends guessing!</span>\n",
      "</td><td>\n",
      "$1.50\n",
      "</td><td>\n",
      "<img src=\"../img/gifts/img6.jpg\"/>\n",
      "</td></tr>\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 2. 处理兄弟标签\n",
    "# BeautifulSoup 的next_siblings() 函数可以让收集表格数据成为简单的事情，尤其是处理带标题行的表格：\n",
    "# 这段代码会打印产品列表里的所有列的产品，第一列表格标题除外\n",
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "html = urlopen(\"http://www.pythonscraping.com/pages/page3.html\")\n",
    "bsObj = BeautifulSoup(html)\n",
    "for sibling in bsObj.find(\"table\",{\"id\":\"giftList\"}).tr.next_siblings:\n",
    "    print(sibling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You\n",
      "Young Frank\n"
     ]
    }
   ],
   "source": [
    "# 正则表达式 regex\n",
    "# (1) 字母“a”至少出现一次；\n",
    "# (2) 后面跟着字母“b”重复5 次；\n",
    "# (3) 后面再跟字母“c”重复任意偶数次；\n",
    "# (4) 最后一位是字母“d”，也可以没有。\n",
    "# 满足上面规则的字符串有：“aaaabbbbbccccd”“aabbbbbcc”等（有无穷多种变化）\n",
    "\n",
    "# 这组规则的正则表达式如下所示：\n",
    "# aa*bbbbb(cc)*(d | )\n",
    "# 第一次看这个字符串会觉得有点儿奇葩，但是当我们把它分解之后就会很清楚了。\n",
    "# • aa*\n",
    "# a 后面跟着的a*（读作a 星）表示“重复任意次a，包括0 次”。这样就可以保证字母a\n",
    "# 至少出现一次。\n",
    "# • bbbbb\n",
    "# 这没有什么特别的——就是5 次b。\n",
    "# • (cc)*\n",
    "# 任意偶数个字符都可以编组，这个规则是用括号两个c，然后后面跟一个星号，表示有\n",
    "# 任意次两个c（也可以是0 次）\n",
    "# • (d|)\n",
    "# 增加一个竖线（|）在表达式里表示“这个或那个”。本例是表示“增加一个后面跟着空\n",
    "# 格的d，或者只有一个空格”。这样我们可以保证字符串的结尾最多是一个后面跟着空\n",
    "# 格的d\n",
    "\n",
    "# 1. 邮箱地址的第一部分至少包括一种内容：大写字母、小写字母、数字0~9、点号（.）、加号（+）或下划线（_）\n",
    "#    [A-Za-z0-9\\._+]+：\n",
    "#    把所有可能的序列和符号放在中括号（不是小括号）里表示“括号中的符号里任何一个”。要注意后面的加号，它表示“这些符号都可以出现多次，\n",
    "#    且至少出现1 次”\n",
    "# 2. 之后，邮箱地址会包含一个@ 符之后，邮箱地址会包含一个@ 符号@：这个符号很直接。@ 符号必须出现在中间位置，有且仅有1 次\n",
    "# 3. 在符合@ 之后，邮箱地址还必须至少包含一个大写或小写字母[A-Za-z]+：\n",
    "# 4. 之后跟一个点号（.） \\.：在域名前必须有一个点号（.）\n",
    "# 5. 最后邮箱地址用com、org、edu、net 结尾\n",
    "\n",
    "# 把上面的规则连接起来，就获得了完整的正则表达式：\n",
    "# [A-Za-z0-9\\._+]+@[A-Za-z]+\\.(com|org|edu|net)\n",
    "\n",
    "\n",
    "#用正規表達式來匹配\n",
    "# compile() 編譯 \n",
    "# match() 匹配\n",
    "# search() 會回傳第一個匹配項目\n",
    "# findall() 會回傳所有不重疊的匹配\n",
    "# split() 會用模式，在匹配處分割來源，並回傳一串字串片段\n",
    "# sub() 會使用另一個取代引數，並將來源內，所有匹配模式的項目換成取代引數\n",
    "#使用match()來取出匹配項目\n",
    "import re \n",
    "source = 'Young Frankn'\n",
    "m = re.match('You',source)\n",
    "if m:#回傳一個物件，查看有哪些匹配？\n",
    "    print(m.group())\n",
    "    \n",
    "    \n",
    "n = re.match('.*Frank',source)#.代表任何單一字元  *代表在它前面的東西，任何數量\n",
    "if n:#回傳一個物件，查看有哪些匹配？\n",
    "    print(n.group())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frank\n"
     ]
    }
   ],
   "source": [
    "#使用search()找出第一個匹配的項目，不需要.*萬用字元\n",
    "n = re.search('Frank',source)#.代表任何單一字元  *代表在它前面的東西，任何數量\n",
    "if n:#回傳一個物件，查看有哪些匹配？\n",
    "    print(n.group())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['n', 'n', 'n']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#使用findall()找到某個單字出現的次數？\n",
    "n = re.findall('n',source)\n",
    "n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ng', 'nk']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#n後面的字元呢？加上.\n",
    "n = re.findall('n.',source)\n",
    "n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ng', 'nk', 'n']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#並未匹配到最後一個n，所以使用？\n",
    "n = re.findall('n.?',source)\n",
    "n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['You', 'g Fra', 'k', '']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#使用split()來分割，碰到n就分割\n",
    "n = re.split('n',source)\n",
    "n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You?g Fra?k?'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#使用sub()來替換匹配，有點像replace\n",
    "n = re.sub('n','?',source)\n",
    "n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#特殊字元\n",
    "# \\d 一個數字\n",
    "# \\D 一個非數字\n",
    "# \\w 一個英數字元\n",
    "# \\W 一個非英數字元\n",
    "# \\s 一個空白字元\n",
    "# \\S 一個非空白字元\n",
    "# \\b 一個單字範圍(介於 \\w和\\W，無論順序為何)\n",
    "# \\B 一個非單字範圍\n",
    "# python string 下的 printable 有100個 ASCII字元\n",
    "import string \n",
    "printable = string.printable\n",
    "len(printable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMN'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "printable[0 : 50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#有哪些是數字？\n",
    "a = re.findall('\\d',printable)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', '_']\n"
     ]
    }
   ],
   "source": [
    "#有哪些字元是數字？字母？或底線？\n",
    "a = re.findall('\\w',printable)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' ', '\\t', '\\n', '\\r', '\\x0b', '\\x0c']\n"
     ]
    }
   ],
   "source": [
    "#哪些是空白？\n",
    "a = re.findall('\\s',printable)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['wish', 'wish']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#使用指定符\n",
    "# a | b 或\n",
    "# . 除了\\n之外的任何字元\n",
    "# ^來源字串的開頭\n",
    "# $來源字串的結尾\n",
    "# prev ?  零或一個prev\n",
    "# prev *  零或多個prev 越多越好\n",
    "# prev *? 零或一個prev 越少越好\n",
    "# prev +  一個或多個prev 越多越好\n",
    "# prev +?  一個或多個prev 越少越好\n",
    "# prev {m} m個連續的prev\n",
    "# prev {m , n} m到n個連續的prev 越多越好\n",
    "# prev {m , n}? m到n個連續的prev 越少越好\n",
    "# [ abc ] a或b或c\n",
    "# [ ^abc ] not(a或b或c)\n",
    "# prev (?= next) prev，如果它後面有next的話\n",
    "# prev (?| next) prev，如果它後面沒有next的話\n",
    "# (?<= prev) next 如果next之前是prev，匹配next\n",
    "# (?<! prev) next 如果next之前不是prev，匹配next\n",
    "source = 'I wish I may,I wish I might ...Have a dish of fish tonight...'\n",
    "#找出任何地方的wish\n",
    "re.findall('wish',source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['wish ', 'wish ', ' fish']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#找出任何地方的wish或fish\n",
    "re.findall('wish | fish',source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#找到開頭的wish\n",
    "re.findall('^wish',source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I wish']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#找到開頭的I wish\n",
    "re.findall('^I wish',source)#連同空格都會辨識"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#找到結尾的fish\n",
    "re.findall('fish$',source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fish tonight...']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#找到結尾的fish tonight...\n",
    "re.findall('fish tonight...$',source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['wish', 'wish', 'fish']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#用ish來尋找w or f\n",
    "re.findall('[wf]ish',source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['w', 'sh', 'w', 'sh', 'h', 'sh', 'sh', 'h']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#尋找一個或多個w,s,h\n",
    "re.findall('[wsh]+',source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ght ', 'ght.']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#尋找後面有非英數字元的ght\n",
    "re.findall('ght\\W',source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I', 'I']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#尋找wish之前的I\n",
    "re.findall('I(?= wish)',source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' wish', ' wish']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#尋找I之後的wish\n",
    "re.findall('(?<=I) wish',source)#一定要空格"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../img/gifts/img1.jpg\n",
      "../img/gifts/img2.jpg\n",
      "../img/gifts/img3.jpg\n",
      "../img/gifts/img4.jpg\n",
      "../img/gifts/img6.jpg\n"
     ]
    }
   ],
   "source": [
    "#直接定位那些标签来查找信息。在本例中，我们直接通过商品图片的文件路径来查找：\n",
    "\n",
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "\n",
    "html = urlopen('http://www.pythonscraping.com/pages/page3.html')\n",
    "bs = BeautifulSoup(html, 'html.parser')\n",
    "images = bs.find_all('img', {'src':re.compile('\\.\\.\\/img\\/gifts/img.*\\.jpg')})#<img src=\"../img/gifts/img2.jpg\">\n",
    "for image in images: \n",
    "    print(image['src'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
