{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      "PassengerId    891 non-null int64\n",
      "Survived       891 non-null int64\n",
      "Pclass         891 non-null int64\n",
      "Name           891 non-null object\n",
      "Sex            891 non-null object\n",
      "Age            714 non-null float64\n",
      "SibSp          891 non-null int64\n",
      "Parch          891 non-null int64\n",
      "Ticket         891 non-null object\n",
      "Fare           891 non-null float64\n",
      "Cabin          204 non-null object\n",
      "Embarked       889 non-null object\n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.6+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#一、数据读入及预处理\n",
    "#使用pandas读入csv文件，读入为pands.DataFrame对象\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "# read data from file\n",
    "data = pd.read_csv('train.csv')\n",
    "print(data.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Sex   Age  Pclass  SibSp  Parch      Fare\n",
      "0      1  22.0       3      1      0    7.2500\n",
      "1      0  38.0       1      1      0   71.2833\n",
      "2      0  26.0       3      0      0    7.9250\n",
      "3      0  35.0       1      1      0   53.1000\n",
      "4      1  35.0       3      0      0    8.0500\n",
      "5      1   0.0       3      0      0    8.4583\n",
      "6      1  54.0       1      0      0   51.8625\n",
      "7      1   2.0       3      3      1   21.0750\n",
      "8      0  27.0       3      0      2   11.1333\n",
      "9      0  14.0       2      1      0   30.0708\n",
      "10     0   4.0       3      1      1   16.7000\n",
      "11     0  58.0       1      0      0   26.5500\n",
      "12     1  20.0       3      0      0    8.0500\n",
      "13     1  39.0       3      1      5   31.2750\n",
      "14     0  14.0       3      0      0    7.8542\n",
      "15     0  55.0       2      0      0   16.0000\n",
      "16     1   2.0       3      4      1   29.1250\n",
      "17     1   0.0       2      0      0   13.0000\n",
      "18     0  31.0       3      1      0   18.0000\n",
      "19     0   0.0       3      0      0    7.2250\n",
      "20     1  35.0       2      0      0   26.0000\n",
      "21     1  34.0       2      0      0   13.0000\n",
      "22     0  15.0       3      0      0    8.0292\n",
      "23     1  28.0       1      0      0   35.5000\n",
      "24     0   8.0       3      3      1   21.0750\n",
      "25     0  38.0       3      1      5   31.3875\n",
      "26     1   0.0       3      0      0    7.2250\n",
      "27     1  19.0       1      3      2  263.0000\n",
      "28     0   0.0       3      0      0    7.8792\n",
      "29     1   0.0       3      0      0    7.8958\n",
      "..   ...   ...     ...    ...    ...       ...\n",
      "861    1  21.0       2      1      0   11.5000\n",
      "862    0  48.0       1      0      0   25.9292\n",
      "863    0   0.0       3      8      2   69.5500\n",
      "864    1  24.0       2      0      0   13.0000\n",
      "865    0  42.0       2      0      0   13.0000\n",
      "866    0  27.0       2      1      0   13.8583\n",
      "867    1  31.0       1      0      0   50.4958\n",
      "868    1   0.0       3      0      0    9.5000\n",
      "869    1   4.0       3      1      1   11.1333\n",
      "870    1  26.0       3      0      0    7.8958\n",
      "871    0  47.0       1      1      1   52.5542\n",
      "872    1  33.0       1      0      0    5.0000\n",
      "873    1  47.0       3      0      0    9.0000\n",
      "874    0  28.0       2      1      0   24.0000\n",
      "875    0  15.0       3      0      0    7.2250\n",
      "876    1  20.0       3      0      0    9.8458\n",
      "877    1  19.0       3      0      0    7.8958\n",
      "878    1   0.0       3      0      0    7.8958\n",
      "879    0  56.0       1      0      1   83.1583\n",
      "880    0  25.0       2      0      1   26.0000\n",
      "881    1  33.0       3      0      0    7.8958\n",
      "882    0  22.0       3      0      0   10.5167\n",
      "883    1  28.0       2      0      0   10.5000\n",
      "884    1  25.0       3      0      0    7.0500\n",
      "885    0  39.0       3      0      5   29.1250\n",
      "886    1  27.0       2      0      0   13.0000\n",
      "887    0  19.0       1      0      0   30.0000\n",
      "888    0   0.0       3      1      2   23.4500\n",
      "889    1  26.0       1      0      0   30.0000\n",
      "890    1  32.0       3      0      0    7.7500\n",
      "\n",
      "[891 rows x 6 columns]\n",
      "     Deceased  Survived\n",
      "0           1         0\n",
      "1           0         1\n",
      "2           0         1\n",
      "3           0         1\n",
      "4           1         0\n",
      "5           1         0\n",
      "6           1         0\n",
      "7           1         0\n",
      "8           0         1\n",
      "9           0         1\n",
      "10          0         1\n",
      "11          0         1\n",
      "12          1         0\n",
      "13          1         0\n",
      "14          1         0\n",
      "15          0         1\n",
      "16          1         0\n",
      "17          0         1\n",
      "18          1         0\n",
      "19          0         1\n",
      "20          1         0\n",
      "21          0         1\n",
      "22          0         1\n",
      "23          0         1\n",
      "24          1         0\n",
      "25          0         1\n",
      "26          1         0\n",
      "27          1         0\n",
      "28          0         1\n",
      "29          1         0\n",
      "..        ...       ...\n",
      "861         1         0\n",
      "862         0         1\n",
      "863         1         0\n",
      "864         1         0\n",
      "865         0         1\n",
      "866         0         1\n",
      "867         1         0\n",
      "868         1         0\n",
      "869         0         1\n",
      "870         1         0\n",
      "871         0         1\n",
      "872         1         0\n",
      "873         1         0\n",
      "874         0         1\n",
      "875         0         1\n",
      "876         1         0\n",
      "877         1         0\n",
      "878         1         0\n",
      "879         0         1\n",
      "880         0         1\n",
      "881         1         0\n",
      "882         1         0\n",
      "883         1         0\n",
      "884         1         0\n",
      "885         1         0\n",
      "886         1         0\n",
      "887         0         1\n",
      "888         1         0\n",
      "889         0         1\n",
      "890         1         0\n",
      "\n",
      "[891 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "#2. 预处理\n",
    "#剔除空数据\n",
    "#将'Sex'字段转换为int类型\n",
    "#选取数值类型的字段，抛弃字符串类型字段\n",
    "# fill nan values with 0\n",
    "data = data.fillna(0)#DataFrame.fillna(value=None, method=None, axis=None, inplace=False, limit=None, downcast=None, **kwargs)\n",
    "\n",
    "#功能：使用指定的方法填充NA / NaN值\n",
    "\n",
    "#参数：value : 变量, 字典, Series, or DataFrame 用于填充缺失值（例如0），或者指定为每个索引（对于Series）或列（对于DataFrame）使用哪个字典/Serise/DataFrame的值。（不在字典/Series/DataFrame中的值不会被填充）这个值不能是一个列表。\n",
    "\n",
    "#method : {‘backfill’, ‘bfill’, ‘pad’, ‘ffill’, None}, 默认值 None ; 在Series中使用方法填充空白（‘backfill’, ‘bfill’向前填充，‘pad’, ‘ffill’向后填充）\n",
    "\n",
    "#axis : {0 or ‘index’, 1 or ‘columns’}\n",
    "\n",
    "#inplace : boolean, 默认值 False。如果为Ture,在原地填满。注意：这将修改次对象上的任何其他视图（例如，DataFrame中的列的无复制贴片）\n",
    "\n",
    "#limit : int, 默认值 None； 如果指定了方法，则这是连续的NaN值的前向/后向填充的最大数量\n",
    "\n",
    "#欄位 survival 是否生存 0=否 pclass艙等 name sex age sibsp(手足或配偶也在船上的數量),parch(雙親或子女也在船上的數量),ticket(車票號碼),fare(旅客費用),cabin(艙位號碼),embarked(登船港口)\n",
    "# convert ['male', 'female'] values of Sex to [1, 0]\n",
    "data['Sex'] = data['Sex'].apply(lambda s: 1 if s == 'male' else 0)\n",
    "# 'Survived' is the label of one class,\n",
    "# add 'Deceased' as the other class\n",
    Python提供了一個簡易的function define：lambda，用完即丟，不著痕跡。讓你實作出很簡單的function(只處理一個運算式)。lambda param1, param2, ... : expression
    #其實就等於
    def fun( param1, param2, ... ) :
       return expression
    "data['Deceased'] = data['Survived'].apply(lambda s: 1 - s)\n",
    "\n",
    "# select features and labels for training\n",
    "dataset_X = data[['Sex', 'Age', 'Pclass', 'SibSp', 'Parch', 'Fare']]\n",
    "dataset_Y = data[['Deceased', 'Survived']]\n",
    "\n",
    "print(dataset_X)\n",
    "print(dataset_Y)\n",
    "\n",
    "#根据先验选出有用的特征字段,例如,妇女和儿童有机会先上救生艇(性别,年龄),课程示例中选取了6个字段,即特征有6个维度\n",
    "#利用 one­hot encoding 预处理标签,标签是一个二维 Vector,如,幸存的标签(1,0),遇难的标签(0, 1)\n",
    "#利用 sk­learn 将训练数据分为训练集和验证集,防止过拟合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3. 将训练数据切分为训练集(training set)和验证集(validation set)\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#為了之後要評估模型的表現，我們也需要將資料切分為訓練與測試資料，\n",
    "#訓練資料是用來建立模型，測試資料則用來評估模型。實務中兩個資料不會有交集\n",
    "#，常見的切分比例是 2/3 作為訓練資料，1/3 作為測試資料。\n",
    "\n",
    "#在接下來的程式我們將 train_test_split() 方法中的 test_size 參數設為 0.25\n",
    "#，另外一個參數 random_state 設為 42 用來確保每次切分資料的結果都相同\n",
    "# split training data and validation set data\n",
    "X_train, X_val, y_train, y_val = train_test_split(dataset_X.values, dataset_Y.values,\n",
    "                                                  test_size=0.2,\n",
    "                                                  random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#使用placeholder声明输入占位符\n",
    "#声明占位符placeholder需要给定三个参数，分别是输入数据的元素类型dtype、维度形状shape也就是每一個維度的大小和占位符名称标识name,ndim是維度的數量,size是整個陣列的大小。\n",
    "# 声明输入数据占位符\n",
    "# shape参数的第一个元素为None，表示可以同时放入任意条记录\n",
    "X = tf.placeholder(tf.float32, shape=[None, 6], name='input')\n",
    "y = tf.placeholder(tf.float32, shape=[None, 2], name='label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tf.random_normal从正态分布中输出随机值\n",
    "#shape：一个一维整数张量或Python数组。代表张量的形状。\n",
    "#mean：数据类型为dtype的张量值或Python值。是正态分布的均值。\n",
    "#stddev：数据类型为dtype的张量值或Python值。是正态分布的标准差。\n",
    "#dtype： 输出的数据类型。\n",
    "#seed：一个Python整数。是随机种子。\n",
    "#name： 操作的名称(可选)\n",
    "# 声明变量\n",
    "weights = tf.Variable(tf.random_normal([6, 2]), name='weights')\n",
    "bias = tf.Variable(tf.zeros([2]), name='bias')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = tf.nn.softmax(tf.matmul(X, weights) + bias)\n",
    "#tf.matmul(a,b,ranspose_a=False,transpose_b=False,_is_sparse=False,_is_sparse=False,ame=None)\n",
    "#函數解說：將a,b兩個矩陣相乘，如果需要事先轉置的話，可以把個別的選項調成True，如果矩陣裏面包括很多0的話，可以調用spare=True轉為更有效率的演算法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用交叉熵作为代价函数\n",
    "cross_entropy = - tf.reduce_sum(y * tf.log(y_pred + 1e-10),\n",
    "                                reduction_indices=1)\n",
    "# 批量样本的代价值为所有样本交叉熵的平均值\n",
    "cost = tf.reduce_mean(cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用随机梯度下降算法优化器来最小化代价，系统自动构建反向传播部分的计算图\n",
    "train_op = tf.train.GradientDescentOptimizer(0.001).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算准确率\n",
    "correct_pred = tf.equal(tf.argmax(y, 1), tf.argmax(y_pred, 1))\n",
    "acc_op = tf.reduce_mean(tf.cast(correct_pred, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001, total loss=6123.308819782\n",
      "Epoch: 0002, total loss=6089.605405431\n",
      "Epoch: 0003, total loss=6045.665538430\n",
      "Epoch: 0004, total loss=5895.276080983\n",
      "Epoch: 0005, total loss=1346.720362250\n",
      "Epoch: 0006, total loss=1193.316551583\n",
      "Epoch: 0007, total loss=1208.721845722\n",
      "Epoch: 0008, total loss=1223.291139721\n",
      "Epoch: 0009, total loss=1211.641917779\n",
      "Epoch: 0010, total loss=1172.887227095\n",
      "Training complete!\n",
      "Accuracy on validation set: 0.664804459\n",
      "Accuracy on validation set (numpy): 0.664804459\n"
     ]
    }
   ],
   "source": [
    "#启动Session，代入数据进行计算。训练结束后使用验证集评估训练效果\n",
    "with tf.Session() as sess:\n",
    "    # variables have to be initialized at the first place\n",
    "    tf.global_variables_initializer().run()\n",
    "\n",
    "    # training loop\n",
    "    for epoch in range(10):\n",
    "        total_loss = 0.\n",
    "        for i in range(len(X_train)):\n",
    "            # prepare feed data and run\n",
    "            feed_dict = {X: [X_train[i]], y: [y_train[i]]}\n",
    "            _, loss = sess.run([train_op, cost], feed_dict=feed_dict)\n",
    "            total_loss += loss\n",
    "        # display loss per epoch\n",
    "        print('Epoch: %04d, total loss=%.9f' % (epoch + 1, total_loss))\n",
    "\n",
    "    print ('Training complete!')\n",
    "    \n",
    "    # Accuracy calculated by TensorFlow\n",
    "    accuracy = sess.run(acc_op, feed_dict={X: X_val, y: y_val})\n",
    "    print(\"Accuracy on validation set: %.9f\" % accuracy)\n",
    "\n",
    "    # Accuracy calculated by NumPy\n",
    "    pred = sess.run(y_pred, feed_dict={X: X_val})\n",
    "    correct = np.equal(np.argmax(pred, 1), np.argmax(y_val, 1))\n",
    "    numpy_accuracy = np.mean(correct.astype(np.float32))\n",
    "    print(\"Accuracy on validation set (numpy): %.9f\" % numpy_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
