{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#ch21_SparkML.ipynb, Spark ML Pipeline多元分類"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'local[*]'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc.master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#step1. 資料準備"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "581012"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rawData=sc.textFile(\"covtype.data\")\n",
    "lines=rawData.map(lambda x:x.split(\",\"))\n",
    "lines.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fieldnum = len(lines.first()) #算欄位數\n",
    "fieldnum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#step2. 建立DataFrame\n",
    "# pyspark.sql.types --> List of data types available.\n",
    "#StructType is a built-in data type in Spark SQL to represent a collection of StructFields that together define a schema or its part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#step2.1 匯入 StringType,StructField,StructType module\n",
    "from pyspark.sql.types import  StringType,StructField,StructType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#step2.2 建立DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#step2.2.1 建立欄位list fields\n",
    "fields = [StructField(\"f\"+str(i), StringType(), True)  #串列生成式\n",
    "               for i in range(fieldnum )]\n",
    "#fro i in range(fieldnum):       i--> 0~54\n",
    "#以StructField() 建立欄位, 'f0','f1','f2',...'f54', 資料型別為 String\n",
    "#結果存放在 fields --> list of string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[StructField(f0,StringType,true),\n",
       " StructField(f1,StringType,true),\n",
       " StructField(f2,StringType,true),\n",
       " StructField(f3,StringType,true),\n",
       " StructField(f4,StringType,true),\n",
       " StructField(f5,StringType,true),\n",
       " StructField(f6,StringType,true),\n",
       " StructField(f7,StringType,true),\n",
       " StructField(f8,StringType,true),\n",
       " StructField(f9,StringType,true),\n",
       " StructField(f10,StringType,true),\n",
       " StructField(f11,StringType,true),\n",
       " StructField(f12,StringType,true),\n",
       " StructField(f13,StringType,true),\n",
       " StructField(f14,StringType,true),\n",
       " StructField(f15,StringType,true),\n",
       " StructField(f16,StringType,true),\n",
       " StructField(f17,StringType,true),\n",
       " StructField(f18,StringType,true),\n",
       " StructField(f19,StringType,true),\n",
       " StructField(f20,StringType,true),\n",
       " StructField(f21,StringType,true),\n",
       " StructField(f22,StringType,true),\n",
       " StructField(f23,StringType,true),\n",
       " StructField(f24,StringType,true),\n",
       " StructField(f25,StringType,true),\n",
       " StructField(f26,StringType,true),\n",
       " StructField(f27,StringType,true),\n",
       " StructField(f28,StringType,true),\n",
       " StructField(f29,StringType,true),\n",
       " StructField(f30,StringType,true),\n",
       " StructField(f31,StringType,true),\n",
       " StructField(f32,StringType,true),\n",
       " StructField(f33,StringType,true),\n",
       " StructField(f34,StringType,true),\n",
       " StructField(f35,StringType,true),\n",
       " StructField(f36,StringType,true),\n",
       " StructField(f37,StringType,true),\n",
       " StructField(f38,StringType,true),\n",
       " StructField(f39,StringType,true),\n",
       " StructField(f40,StringType,true),\n",
       " StructField(f41,StringType,true),\n",
       " StructField(f42,StringType,true),\n",
       " StructField(f43,StringType,true),\n",
       " StructField(f44,StringType,true),\n",
       " StructField(f45,StringType,true),\n",
       " StructField(f46,StringType,true),\n",
       " StructField(f47,StringType,true),\n",
       " StructField(f48,StringType,true),\n",
       " StructField(f49,StringType,true),\n",
       " StructField(f50,StringType,true),\n",
       " StructField(f51,StringType,true),\n",
       " StructField(f52,StringType,true),\n",
       " StructField(f53,StringType,true),\n",
       " StructField(f54,StringType,true)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fields #檢視"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#step2.2.2 建立schema\n",
    "schema = StructType(fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType(List(StructField(f0,StringType,true),StructField(f1,StringType,true),StructField(f2,StringType,true),StructField(f3,StringType,true),StructField(f4,StringType,true),StructField(f5,StringType,true),StructField(f6,StringType,true),StructField(f7,StringType,true),StructField(f8,StringType,true),StructField(f9,StringType,true),StructField(f10,StringType,true),StructField(f11,StringType,true),StructField(f12,StringType,true),StructField(f13,StringType,true),StructField(f14,StringType,true),StructField(f15,StringType,true),StructField(f16,StringType,true),StructField(f17,StringType,true),StructField(f18,StringType,true),StructField(f19,StringType,true),StructField(f20,StringType,true),StructField(f21,StringType,true),StructField(f22,StringType,true),StructField(f23,StringType,true),StructField(f24,StringType,true),StructField(f25,StringType,true),StructField(f26,StringType,true),StructField(f27,StringType,true),StructField(f28,StringType,true),StructField(f29,StringType,true),StructField(f30,StringType,true),StructField(f31,StringType,true),StructField(f32,StringType,true),StructField(f33,StringType,true),StructField(f34,StringType,true),StructField(f35,StringType,true),StructField(f36,StringType,true),StructField(f37,StringType,true),StructField(f38,StringType,true),StructField(f39,StringType,true),StructField(f40,StringType,true),StructField(f41,StringType,true),StructField(f42,StringType,true),StructField(f43,StringType,true),StructField(f44,StringType,true),StructField(f45,StringType,true),StructField(f46,StringType,true),StructField(f47,StringType,true),StructField(f48,StringType,true),StructField(f49,StringType,true),StructField(f50,StringType,true),StructField(f51,StringType,true),StructField(f52,StringType,true),StructField(f53,StringType,true),StructField(f54,StringType,true)))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#step2.2.3 檢視schema\n",
    "schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#step2.3 以spark.createDataFrame(RDD,schema) 建立spark DataFrame 'covtype_df'\n",
    "covtype_df = spark.createDataFrame(lines, schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['f0', 'f1', 'f2', 'f3', 'f4', 'f5', 'f6', 'f7', 'f8', 'f9', 'f10', 'f11', 'f12', 'f13', 'f14', 'f15', 'f16', 'f17', 'f18', 'f19', 'f20', 'f21', 'f22', 'f23', 'f24', 'f25', 'f26', 'f27', 'f28', 'f29', 'f30', 'f31', 'f32', 'f33', 'f34', 'f35', 'f36', 'f37', 'f38', 'f39', 'f40', 'f41', 'f42', 'f43', 'f44', 'f45', 'f46', 'f47', 'f48', 'f49', 'f50', 'f51', 'f52', 'f53', 'f54']\n"
     ]
    }
   ],
   "source": [
    "#檢視covtype_df 的欄位\n",
    "print covtype_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- f0: string (nullable = true)\n",
      " |-- f1: string (nullable = true)\n",
      " |-- f2: string (nullable = true)\n",
      " |-- f3: string (nullable = true)\n",
      " |-- f4: string (nullable = true)\n",
      " |-- f5: string (nullable = true)\n",
      " |-- f6: string (nullable = true)\n",
      " |-- f7: string (nullable = true)\n",
      " |-- f8: string (nullable = true)\n",
      " |-- f9: string (nullable = true)\n",
      " |-- f10: string (nullable = true)\n",
      " |-- f11: string (nullable = true)\n",
      " |-- f12: string (nullable = true)\n",
      " |-- f13: string (nullable = true)\n",
      " |-- f14: string (nullable = true)\n",
      " |-- f15: string (nullable = true)\n",
      " |-- f16: string (nullable = true)\n",
      " |-- f17: string (nullable = true)\n",
      " |-- f18: string (nullable = true)\n",
      " |-- f19: string (nullable = true)\n",
      " |-- f20: string (nullable = true)\n",
      " |-- f21: string (nullable = true)\n",
      " |-- f22: string (nullable = true)\n",
      " |-- f23: string (nullable = true)\n",
      " |-- f24: string (nullable = true)\n",
      " |-- f25: string (nullable = true)\n",
      " |-- f26: string (nullable = true)\n",
      " |-- f27: string (nullable = true)\n",
      " |-- f28: string (nullable = true)\n",
      " |-- f29: string (nullable = true)\n",
      " |-- f30: string (nullable = true)\n",
      " |-- f31: string (nullable = true)\n",
      " |-- f32: string (nullable = true)\n",
      " |-- f33: string (nullable = true)\n",
      " |-- f34: string (nullable = true)\n",
      " |-- f35: string (nullable = true)\n",
      " |-- f36: string (nullable = true)\n",
      " |-- f37: string (nullable = true)\n",
      " |-- f38: string (nullable = true)\n",
      " |-- f39: string (nullable = true)\n",
      " |-- f40: string (nullable = true)\n",
      " |-- f41: string (nullable = true)\n",
      " |-- f42: string (nullable = true)\n",
      " |-- f43: string (nullable = true)\n",
      " |-- f44: string (nullable = true)\n",
      " |-- f45: string (nullable = true)\n",
      " |-- f46: string (nullable = true)\n",
      " |-- f47: string (nullable = true)\n",
      " |-- f48: string (nullable = true)\n",
      " |-- f49: string (nullable = true)\n",
      " |-- f50: string (nullable = true)\n",
      " |-- f51: string (nullable = true)\n",
      " |-- f52: string (nullable = true)\n",
      " |-- f53: string (nullable = true)\n",
      " |-- f54: string (nullable = true)\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#檢視covtype_df 的schema, printSchema()\n",
    "print covtype_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#step2.4 將欄位資料型別由string 轉成 double\n",
    "from pyspark.sql.functions import col  #import col module, 用來存取欄位\n",
    "covtype_df= covtype_df.select([ col(column).cast(\"double\").alias(column) \n",
    "                                          for column in covtype_df.columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- f0: double (nullable = true)\n",
      " |-- f1: double (nullable = true)\n",
      " |-- f2: double (nullable = true)\n",
      " |-- f3: double (nullable = true)\n",
      " |-- f4: double (nullable = true)\n",
      " |-- f5: double (nullable = true)\n",
      " |-- f6: double (nullable = true)\n",
      " |-- f7: double (nullable = true)\n",
      " |-- f8: double (nullable = true)\n",
      " |-- f9: double (nullable = true)\n",
      " |-- f10: double (nullable = true)\n",
      " |-- f11: double (nullable = true)\n",
      " |-- f12: double (nullable = true)\n",
      " |-- f13: double (nullable = true)\n",
      " |-- f14: double (nullable = true)\n",
      " |-- f15: double (nullable = true)\n",
      " |-- f16: double (nullable = true)\n",
      " |-- f17: double (nullable = true)\n",
      " |-- f18: double (nullable = true)\n",
      " |-- f19: double (nullable = true)\n",
      " |-- f20: double (nullable = true)\n",
      " |-- f21: double (nullable = true)\n",
      " |-- f22: double (nullable = true)\n",
      " |-- f23: double (nullable = true)\n",
      " |-- f24: double (nullable = true)\n",
      " |-- f25: double (nullable = true)\n",
      " |-- f26: double (nullable = true)\n",
      " |-- f27: double (nullable = true)\n",
      " |-- f28: double (nullable = true)\n",
      " |-- f29: double (nullable = true)\n",
      " |-- f30: double (nullable = true)\n",
      " |-- f31: double (nullable = true)\n",
      " |-- f32: double (nullable = true)\n",
      " |-- f33: double (nullable = true)\n",
      " |-- f34: double (nullable = true)\n",
      " |-- f35: double (nullable = true)\n",
      " |-- f36: double (nullable = true)\n",
      " |-- f37: double (nullable = true)\n",
      " |-- f38: double (nullable = true)\n",
      " |-- f39: double (nullable = true)\n",
      " |-- f40: double (nullable = true)\n",
      " |-- f41: double (nullable = true)\n",
      " |-- f42: double (nullable = true)\n",
      " |-- f43: double (nullable = true)\n",
      " |-- f44: double (nullable = true)\n",
      " |-- f45: double (nullable = true)\n",
      " |-- f46: double (nullable = true)\n",
      " |-- f47: double (nullable = true)\n",
      " |-- f48: double (nullable = true)\n",
      " |-- f49: double (nullable = true)\n",
      " |-- f50: double (nullable = true)\n",
      " |-- f51: double (nullable = true)\n",
      " |-- f52: double (nullable = true)\n",
      " |-- f53: double (nullable = true)\n",
      " |-- f54: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#再次檢視schema, string-> double\n",
    "covtype_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#**********************************************\n",
    "#上述資料轉換,可用pandas 套件處理\n",
    "import pandas as pd \n",
    "pd_df=pd.read_csv(\"covtype.data\") \n",
    "#建立欄位字串串列 fields\n",
    "fields=[\"f\"+str(i) for i in range(55)] \n",
    "#更改column name\n",
    "pd_df.columns=fields\n",
    "#將int 改為 float\n",
    "pd_df=pd_df.applymap(lambda x:float(x))\n",
    "#sqlContext.createDataFrame()\n",
    "covtype_df=sqlContext.createDataFrame(pd_df)\n",
    "#*********************************************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['f0', 'f1', 'f2', 'f3', 'f4', 'f5', 'f6', 'f7', 'f8', 'f9', 'f10', 'f11', 'f12', 'f13', 'f14', 'f15', 'f16', 'f17', 'f18', 'f19', 'f20', 'f21', 'f22', 'f23', 'f24', 'f25', 'f26', 'f27', 'f28', 'f29', 'f30', 'f31', 'f32', 'f33', 'f34', 'f35', 'f36', 'f37', 'f38', 'f39', 'f40', 'f41', 'f42', 'f43', 'f44', 'f45', 'f46', 'f47', 'f48', 'f49', 'f50', 'f51', 'f52', 'f53']\n"
     ]
    }
   ],
   "source": [
    "#step2.5 建立feature column list\n",
    "#              從DataFrame covtype_df 擷取 [:54]\n",
    "featuresCols=covtype_df.columns[:54]\n",
    "print(featuresCols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#step2.6 建立label column, 並調整label 值\n",
    "#step2.6.1 以DataFrame.withColumn(), 建立一個新欄位 \"label\",其值為原\"f54\"欄位值減一\n",
    "#                 這是因為在DecisionTreeClassifier algorithm 中,規定 label 值需由0開始, \n",
    "#                 原始 label \"f54\"值,是 1,2,...,7, 調整後label值為 0,1,2,...,6\n",
    "covtype_df=covtype_df.withColumn(\"label\", covtype_df[\"f54\"] -1)\n",
    "#step2.6.2 以DataFrame.drop() 將原先的欄位 \"f54\" drop \n",
    "covtype_df=covtype_df.drop(\"f54\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----+---+-----+---+-----+-----+-----+-----+------+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+-----+\n",
      "|    f0|  f1| f2|   f3| f4|   f5|   f6|   f7|   f8|    f9|f10|f11|f12|f13|f14|f15|f16|f17|f18|f19|f20|f21|f22|f23|f24|f25|f26|f27|f28|f29|f30|f31|f32|f33|f34|f35|f36|f37|f38|f39|f40|f41|f42|f43|f44|f45|f46|f47|f48|f49|f50|f51|f52|f53|label|\n",
      "+------+----+---+-----+---+-----+-----+-----+-----+------+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+-----+\n",
      "|2596.0|51.0|3.0|258.0|0.0|510.0|221.0|232.0|148.0|6279.0|1.0|0.0|0.0|0.0|0.0|0.0|0.0|0.0|0.0|0.0|0.0|0.0|0.0|0.0|0.0|0.0|0.0|0.0|0.0|0.0|0.0|0.0|0.0|0.0|0.0|0.0|0.0|0.0|0.0|0.0|0.0|0.0|1.0|0.0|0.0|0.0|0.0|0.0|0.0|0.0|0.0|0.0|0.0|0.0|  4.0|\n",
      "+------+----+---+-----+---+-----+-----+-----+-----+------+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+-----+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#step2.6.3 以DataFrame.show() 顯示第一筆修改後的 資料\n",
    "covtype_df.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[f0: double, f1: double, f2: double, f3: double, f4: double, f5: double, f6: double, f7: double, f8: double, f9: double, f10: double, f11: double, f12: double, f13: double, f14: double, f15: double, f16: double, f17: double, f18: double, f19: double, f20: double, f21: double, f22: double, f23: double, f24: double, f25: double, f26: double, f27: double, f28: double, f29: double, f30: double, f31: double, f32: double, f33: double, f34: double, f35: double, f36: double, f37: double, f38: double, f39: double, f40: double, f41: double, f42: double, f43: double, f44: double, f45: double, f46: double, f47: double, f48: double, f49: double, f50: double, f51: double, f52: double, f53: double, label: double]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "covtype_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[f0: double, f1: double, f2: double, f3: double, f4: double, f5: double, f6: double, f7: double, f8: double, f9: double, f10: double, f11: double, f12: double, f13: double, f14: double, f15: double, f16: double, f17: double, f18: double, f19: double, f20: double, f21: double, f22: double, f23: double, f24: double, f25: double, f26: double, f27: double, f28: double, f29: double, f30: double, f31: double, f32: double, f33: double, f34: double, f35: double, f36: double, f37: double, f38: double, f39: double, f40: double, f41: double, f42: double, f43: double, f44: double, f45: double, f46: double, f47: double, f48: double, f49: double, f50: double, f51: double, f52: double, f53: double, label: double]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#step2.7 以DataFrame.randomSplit() 將資料分為 train_df與 test_df\n",
    "#              比例為 7:3, 並以DataFrame.cache() 將資料cache 在MM\n",
    "train_df, test_df = covtype_df.randomSplit([0.7, 0.3]) \n",
    "train_df.cache()\n",
    "test_df.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#step3. 建立 Machine Learning Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#step3.1 import Pipeline, VectorAssembler, DecisionTreeClassifier module\n",
    "from pyspark.ml import Pipeline  \n",
    "from pyspark.ml.feature import   VectorAssembler\n",
    "from pyspark.ml.classification import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#step3.2 建立pipeline\n",
    "#step3.2.1 建立 VectorAssembler 物件 'vectorAssembler'\n",
    "#                將step2.5建立的featuresCols 整合成一個 ''features' Vector \n",
    "vectorAssembler = VectorAssembler(inputCols=featuresCols, \n",
    "                                                               outputCol=\"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#step3.2.2 建立DecisionTreeClassifier 物件 'dt'\n",
    "#                maxDepth=5, maxBins=20, featuersCol 是 step3.2.1 產生的 Vector \"features\"\n",
    "dt=DecisionTreeClassifier(labelCol=\"label\",featuresCol=\"features\",\n",
    "                          maxDepth=5,maxBins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#step3.2.3 建立 Pipeline物件 'dt_pipeline'\n",
    "dt_pipeline=Pipeline(stages=[vectorAssembler, dt])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[VectorAssembler_4215b6b5f5c705c2f7ed,\n",
       " DecisionTreeClassifier_447dbb35e84fdbf76bb7]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#step3.2.4 查看 pipeline stages, Pipeline.getStages()\n",
    "dt_pipeline.getStages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#step4. 使用Pipeline 'df_pipeline' 進行資料處理與訓練\n",
    "#            Pipeline 'df_pipeline' 是一個 Estimator, 所以我們使用Pipeline.fit(DataFrame)\n",
    "#            以train_df 當參數,作訓練\n",
    "#           訓練所得的結果是一個PipelineModel物件 (pyspark.ml.pipeline.PipelineModel) 'pipelineModel' (Transformer 物件)\n",
    "#           pipelineModel 的第2個 stages 是決策樹分類器模型(DecisionTreeClassificationModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#step4.1 使用Pipeline.fit() 進行訓練\n",
    "pipelineModel=dt_pipeline.fit(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.ml.pipeline.PipelineModel"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(pipelineModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassificationModel (uid=DecisionTreeClassifier_447dbb35e84fdbf76bb7) of depth 5 with 63 nodes"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#step4.2 查看訓練完後的決策樹模型\n",
    "pipelineModel.stages[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassificationModel (uid=DecisionTreeClassifier_447dbb35e84fdbf76bb7) of depth 5 with 63 nodes\n",
      "  If (feature 0 <= 3057.0)\n",
      "   If (feature 0 <= 2582.0)\n",
      "    If (feature 10 <= 0.0)\n",
      "     If (feature 0 <= 2405.0)\n",
      "      If (feature 3 <= 0.0)\n",
      "       Predict: 3.0\n",
      "      Else (feature 3 > 0.0)\n",
      "       Predict: 2.0\n",
      "     Else (feature 0 > 2405.0)\n",
      "      If (feature 17 <= 0.0)\n",
      "       Predict: 2.0\n",
      "      Else (feature 17 > 0.0)\n",
      "       Predict: 2.0\n",
      "    Else (feature 10 > 0.0)\n",
      "     If (feature 9 <= 4929\n"
     ]
    }
   ],
   "source": [
    "#step4.3 查看訓練完後的決策樹模型規則,DecisionTreeClassificationModel.toDebugString 屬性\n",
    "print pipelineModel.stages[1].toDebugString[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#step5. 使用pipelineModel 進行預測"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#step5.1 使用pipelineModel.transform(DataFrame), 參數test_df進行預測\n",
    "#              預測結果是 DataFrame 物件 'predicted'\n",
    "predicted = pipelineModel.transform(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['f0', 'f1', 'f2', 'f3', 'f4', 'f5', 'f6', 'f7', 'f8', 'f9', 'f10', 'f11', 'f12', 'f13', 'f14', 'f15', 'f16', 'f17', 'f18', 'f19', 'f20', 'f21', 'f22', 'f23', 'f24', 'f25', 'f26', 'f27', 'f28', 'f29', 'f30', 'f31', 'f32', 'f33', 'f34', 'f35', 'f36', 'f37', 'f38', 'f39', 'f40', 'f41', 'f42', 'f43', 'f44', 'f45', 'f46', 'f47', 'f48', 'f49', 'f50', 'f51', 'f52', 'f53', 'label', 'features', 'rawPrediction', 'probability', 'prediction']\n"
     ]
    }
   ],
   "source": [
    "#step5.2 檢視predicted欄位, 增加 'rawPrediction', 'probability', 'prediction' 3個欄位\n",
    "print predicted .columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+-----+----------+\n",
      "|            features|       rawPrediction|         probability|label|prediction|\n",
      "+--------------------+--------------------+--------------------+-----+----------+\n",
      "|(54,[0,1,2,3,4,5,...|[0.0,447.0,12133....|[0.0,0.0237601658...|  2.0|       2.0|\n",
      "|(54,[0,1,2,3,4,5,...|[0.0,447.0,12133....|[0.0,0.0237601658...|  5.0|       2.0|\n",
      "|(54,[0,1,2,3,4,5,...|[0.0,447.0,12133....|[0.0,0.0237601658...|  5.0|       2.0|\n",
      "|(54,[0,1,2,3,4,5,...|[0.0,447.0,12133....|[0.0,0.0237601658...|  2.0|       2.0|\n",
      "|(54,[0,1,2,3,4,5,...|[0.0,447.0,12133....|[0.0,0.0237601658...|  2.0|       2.0|\n",
      "|(54,[0,1,2,3,4,5,...|[0.0,447.0,12133....|[0.0,0.0237601658...|  5.0|       2.0|\n",
      "|(54,[0,1,2,3,4,5,...|[0.0,447.0,12133....|[0.0,0.0237601658...|  2.0|       2.0|\n",
      "|(54,[0,1,2,3,4,5,...|[0.0,447.0,12133....|[0.0,0.0237601658...|  5.0|       2.0|\n",
      "|(54,[0,1,2,3,4,5,...|[0.0,447.0,12133....|[0.0,0.0237601658...|  5.0|       2.0|\n",
      "|(54,[0,1,2,3,4,5,...|[0.0,447.0,12133....|[0.0,0.0237601658...|  2.0|       2.0|\n",
      "+--------------------+--------------------+--------------------+-----+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#step5.3 檢視預測結果的前10筆\n",
    "predicted.select('features', 'rawPrediction', 'probability', 'label','prediction').show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(probability=DenseVector([0.0, 0.0238, 0.6449, 0.0612, 0.0, 0.2701, 0.0]), prediction=2.0),\n",
       " Row(probability=DenseVector([0.0, 0.0238, 0.6449, 0.0612, 0.0, 0.2701, 0.0]), prediction=2.0),\n",
       " Row(probability=DenseVector([0.0, 0.0238, 0.6449, 0.0612, 0.0, 0.2701, 0.0]), prediction=2.0),\n",
       " Row(probability=DenseVector([0.0, 0.0238, 0.6449, 0.0612, 0.0, 0.2701, 0.0]), prediction=2.0),\n",
       " Row(probability=DenseVector([0.0, 0.0238, 0.6449, 0.0612, 0.0, 0.2701, 0.0]), prediction=2.0),\n",
       " Row(probability=DenseVector([0.0, 0.0238, 0.6449, 0.0612, 0.0, 0.2701, 0.0]), prediction=2.0),\n",
       " Row(probability=DenseVector([0.0, 0.0238, 0.6449, 0.0612, 0.0, 0.2701, 0.0]), prediction=2.0),\n",
       " Row(probability=DenseVector([0.0, 0.0238, 0.6449, 0.0612, 0.0, 0.2701, 0.0]), prediction=2.0),\n",
       " Row(probability=DenseVector([0.0, 0.0238, 0.6449, 0.0612, 0.0, 0.2701, 0.0]), prediction=2.0),\n",
       " Row(probability=DenseVector([0.0, 0.0238, 0.6449, 0.0612, 0.0, 0.2701, 0.0]), prediction=2.0)]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#step5.4 檢視預測結果與機率\n",
    "predicted.select('probability', 'prediction').take(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 21.5\t評估模型的準確率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "evaluator = MulticlassClassificationEvaluator(\n",
    "                            labelCol=\"label\", predictionCol=\"prediction\", \n",
    "                            metricName=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7005240585294252"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions=pipelineModel.transform(test_df)\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#21.6\t使用TrainValidation進行訓練評估找出最佳模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.tuning import ParamGridBuilder,TrainValidationSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "paramGrid = ParamGridBuilder()\\\n",
    "  .addGrid(dt.impurity, [ \"gini\",\"entropy\"])\\\n",
    "  .addGrid(dt.maxDepth, [ 10,15,25])\\\n",
    "  .addGrid(dt.maxBins, [30,40,50])\\\n",
    "  .build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tvs = TrainValidationSplit(estimator=dt,evaluator=evaluator,\n",
    "                  estimatorParamMaps=paramGrid,trainRatio=0.8)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tvs_pipeline = Pipeline(stages=[vectorAssembler , tvs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tvs_pipelineModel =tvs_pipeline.fit(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassificationModel (uid=DecisionTreeClassifier_4e15848b4a4cc2cb804d) of depth 25 with 47505 nodes\n",
      "  If (feature 0 <= 2717.0)\n",
      "   If (feature 0 <= 2519.0)\n",
      "    If (feature 0 <= 2407.0)\n",
      "     If (feature 23 <= 0.0)\n",
      "      If (feature 3 <= 0.0)\n",
      "       If (feature 13 <= 0.0)\n",
      "        If (feature 9 <= 603.0)\n",
      "         If (feature 16 <= 0.0)\n",
      "          Predict: 5.0\n",
      "         Else (feature 16 > 0.0)\n",
      "          If (feature 5 <= 379.0)\n",
      "           Predict: 5.0\n",
      "          Else (feature 5 > 379.0)\n",
      "      \n"
     ]
    }
   ],
   "source": [
    "bestModel=tvs_pipelineModel.stages[1].bestModel\n",
    "print bestModel.toDebugString[:500]   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----+----+-----+----+-----+-----+----------+\n",
      "|    海拔|  方位|  斜率| 垂直距離|水平距離|   陰影|label|prediction|\n",
      "+------+----+----+-----+----+-----+-----+----------+\n",
      "|1863.0|37.0|17.0|120.0|18.0| 90.0|  5.0|       5.0|\n",
      "|1866.0|23.0|14.0| 85.0|16.0|108.0|  2.0|       2.0|\n",
      "|1871.0|22.0|22.0| 60.0|12.0| 85.0|  5.0|       5.0|\n",
      "|1871.0|36.0|19.0|134.0|26.0|120.0|  5.0|       5.0|\n",
      "|1874.0|18.0|14.0|  0.0| 0.0| 90.0|  5.0|       2.0|\n",
      "|1877.0|19.0|18.0| 85.0|25.0|108.0|  2.0|       2.0|\n",
      "|1879.0|18.0|14.0|  0.0| 0.0|120.0|  5.0|       2.0|\n",
      "|1880.0|13.0|23.0| 90.0|29.0| 67.0|  5.0|       5.0|\n",
      "|1883.0|27.0|24.0|120.0|24.0|108.0|  5.0|       5.0|\n",
      "|1883.0|29.0|24.0| 60.0|24.0|108.0|  5.0|       5.0|\n",
      "+------+----+----+-----+----+-----+-----+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = tvs_pipelineModel.transform(test_df)\n",
    "result=predictions.withColumnRenamed(\"f0\", \"海拔\") \\\n",
    "                                           .withColumnRenamed(\"f1\", \"方位\") \\\n",
    "                                           .withColumnRenamed(\"f2\", \"斜率\") \\\n",
    "                                           .withColumnRenamed(\"f3\", \"垂直距離\") \\\n",
    "                                           .withColumnRenamed(\"f4\", \"水平距離\") \\\n",
    "                                           .withColumnRenamed(\"f5\", \"陰影\")           \n",
    "result.select(\"海拔\",\"方位\",\"斜率\",\"垂直距離\" , \"水平距離\",\"陰影\",\"label\",\"prediction\").show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9283691115086464"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = evaluator.evaluate(predictions)\n",
    "accuracy "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
